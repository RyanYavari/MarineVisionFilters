{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanYavari/MarineVisionFilters/blob/main/law_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLeTU6_GDeis"
      },
      "source": [
        "Law's Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N-SkDkltnHO",
        "outputId": "368a11fb-94b9-4c1d-f3b0-48b421076d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u3r4hy64g9z"
      },
      "outputs": [],
      "source": [
        "# computing the local energy over a window of the image\n",
        "def compute_texture_energy(filtered_img, window_size):\n",
        "    # creating window kernel initialized to 1.0\n",
        "    kernel = np.ones((window_size, window_size), dtype=np.float32)\n",
        "    # normalizing kernel\n",
        "    kernel = kernel / (window_size ** 2)\n",
        "\n",
        "    # Compute the local sum of the absolute values of the filtered image\n",
        "    texture_energy = cv2.filter2D(np.abs(filtered_img), -1, kernel)\n",
        "    return texture_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Law's function that takes information from greyscale image"
      ],
      "metadata": {
        "id": "hoYa6T_E0i5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Isl-r_BTw5hi"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def generate_laws(input_img, input_img_path, laws_filters, window_size, texture_count):\n",
        "    # converting to cv2 greyscale\n",
        "    input_img_grey = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # convolving each filter with each image\n",
        "    filtered_images = [cv2.filter2D(input_img_grey, -1, kernel) for kernel in laws_filters]\n",
        "\n",
        "    # computing texture energies\n",
        "    texture_energies = [compute_texture_energy(img, window_size) for img in filtered_images]\n",
        "\n",
        "    # creating feature vectors the length of the energies\n",
        "    feature_vectors = np.zeros((input_img_grey.shape[0], input_img_grey.shape[1], len(texture_energies)))\n",
        "\n",
        "    # populate the feature vectors\n",
        "    for i, energy_map in enumerate(texture_energies):\n",
        "        feature_vectors[:, :, i] = energy_map\n",
        "\n",
        "    # reshaping for clustering\n",
        "    num_pixels = feature_vectors.shape[0] * feature_vectors.shape[1]\n",
        "    feature_vectors_2d = feature_vectors.reshape(num_pixels, -1) # shaping so that each row is a sample, and each column is a feature\n",
        "\n",
        "    # normalizing feature vectors, so that each feature has a mean of 0\n",
        "    # each feature will contribute equally to k means clustering\n",
        "    scaler = StandardScaler()\n",
        "    feature_vectors_normalized = scaler.fit_transform(feature_vectors_2d)\n",
        "\n",
        "    # apply k-means clustering\n",
        "    k = texture_count  # number of textures to detect\n",
        "    kmeans = KMeans(n_clusters=k, random_state=18)\n",
        "    kmeans.fit(feature_vectors_normalized)\n",
        "    cluster_labels = kmeans.labels_\n",
        "\n",
        "    # reshape the cluster labels back to the 2D image shape\n",
        "    segmentation_map = cluster_labels.reshape(feature_vectors.shape[0], feature_vectors.shape[1])\n",
        "\n",
        "    # creating color map for visualization\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(segmentation_map, cmap='nipy_spectral')\n",
        "\n",
        "    # extract the base name and extension of the input image\n",
        "    base_name = os.path.splitext(os.path.basename(input_img_path))[0]\n",
        "    output_dir = '/content/drive/Shareddrives/visionFinal/Laws_Images'\n",
        "    output_file = f\"{output_dir}/{base_name}_segmented.png\"\n",
        "\n",
        "    # save the image\n",
        "    plt.savefig(output_file)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Color Law's function that takes information from each hsv channel **Takes a long time to run (at least 5 mins)**"
      ],
      "metadata": {
        "id": "qvPQQXSm0ttT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def generate_laws_color(input_img, input_img_path, laws_filters, window_size, texture_count):\n",
        "    # splitting input images into color channels hsv\n",
        "    input_img_hsv = cv2.cvtColor(input_img, cv2.COLOR_BGR2HSV)\n",
        "    # crerating list of channel images\n",
        "    channels = cv2.split(input_img_hsv)\n",
        "\n",
        "    # creating list to store texture energies for all channels\n",
        "    all_texture_energies = []\n",
        "\n",
        "    for channel in channels:\n",
        "        # convolving each filter with each channel of the image\n",
        "        filtered_images = [cv2.filter2D(channel, -1, kernel) for kernel in laws_filters]\n",
        "\n",
        "        # computing texture energies\n",
        "        texture_energies = [compute_texture_energy(img, window_size) for img in filtered_images]\n",
        "\n",
        "        # adding texture energies of this channel to the list\n",
        "        all_texture_energies.extend(texture_energies)\n",
        "\n",
        "    height, width = channels[0].shape\n",
        "\n",
        "    # creating feature vectors the length of the energies from all channels\n",
        "    feature_vectors = np.zeros((height, width, len(texture_energies))) # these vectors are 3 times larger vs greyscale\n",
        "\n",
        "    # populate the feature vectors\n",
        "    for i, energy_map in enumerate(texture_energies):\n",
        "        feature_vectors[:, :, i] = energy_map\n",
        "\n",
        "    # reshaping for clustering\n",
        "    num_pixels = feature_vectors.shape[0] * feature_vectors.shape[1]\n",
        "    feature_vectors_2d = feature_vectors.reshape(num_pixels, -1) # shaping so that each row is a sample, and each column is a feature\n",
        "\n",
        "    # normalizing feature vectors, so that each feature has a mean of 0\n",
        "    # each feature will contribute equally to k means clustering\n",
        "    scaler = StandardScaler()\n",
        "    feature_vectors_normalized = scaler.fit_transform(feature_vectors_2d)\n",
        "\n",
        "    # apply k-means clustering\n",
        "    k = texture_count  # number of textures to detect\n",
        "    kmeans = KMeans(n_clusters=k, random_state=18) # random state is a random seed number\n",
        "    kmeans.fit(feature_vectors_normalized) #\n",
        "    cluster_labels = kmeans.labels_\n",
        "\n",
        "    # reshape the cluster labels back to the 2D image shape\n",
        "    segmentation_map = cluster_labels.reshape(feature_vectors.shape[0], feature_vectors.shape[1])\n",
        "\n",
        "    # creating color map for visualization\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(segmentation_map, cmap='nipy_spectral') # cmap defines the color scheme\n",
        "\n",
        "    # extract the base name and extension of the input image\n",
        "    base_name = os.path.splitext(os.path.basename(input_img_path))[0]\n",
        "    output_dir = '/content/drive/Shareddrives/visionFinal/Laws_Images_Color'\n",
        "    output_file = f\"{output_dir}/{base_name}_color_segmented.png\"\n",
        "\n",
        "    # save the image\n",
        "    plt.savefig(output_file)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "b003POpguZpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Main\" function"
      ],
      "metadata": {
        "id": "KKCf1x7y1Bso"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ5Lnlkm5muM",
        "outputId": "5b8fa12a-0acb-4a17-a1f5-8f069d9a5df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# define the 1D vectors\n",
        "L5 = np.array([1, 4, 6, 4, 1]) #Level\n",
        "E5 = np.array([-1, -2, 0, 2, 1]) #Edge\n",
        "S5 = np.array([-1, 0, 2, 0, -1]) #Spot\n",
        "R5 = np.array([1, -4, 6, -4, 1]) #Ripple\n",
        "W5 = np.array([-1, 2, 0, -2, 1]) #Wave\n",
        "\n",
        "# creating Laws masks\n",
        "laws_filters = []\n",
        "for vec1 in (L5, E5, S5, R5, W5):\n",
        "  for vec2 in (L5, E5, S5, R5, W5):\n",
        "    # adding outer product of the vectors to filters list\n",
        "    laws_filters.append(np.outer(vec1, vec2))\n",
        "\n",
        "input_folder = '/content/drive/Shareddrives/visionFinal/ARMSPLATES'\n",
        "\n",
        "window_size = 15 # how large should the texture window be\n",
        "texture_count = 10 # number of textures to search for in image\n",
        "\n",
        "# loop over all images in the input folder\n",
        "for image_path in glob.glob(os.path.join(input_folder, '*.ppm')):\n",
        "    # reading the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # call the generate_laws function\n",
        "    generate_laws(image, image_path, laws_filters, window_size, texture_count)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
